# -*- coding: utf-8 -*-
"""Predict Movie Licensing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1450VcWcKWYMzm28GMtfrigcH4Cx-ty1v

**PREDICT MOVIE LICENSING**
"""

# Import necessary libraries for exercise
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split #library for splitting training data into train and test
from sklearn.metrics import accuracy_score # Library for validating the model
from sklearn.ensemble import RandomForestClassifier # The model imported to be used for training the data
from sklearn.preprocessing import LabelEncoder # Library for encoding categorical variables
import matplotlib.pyplot as plt # Library for data visualization
import seaborn as sns # Library for data visualization
from sklearn.impute import SimpleImputer
from scipy import stats # Library for point biserial correlation

# Load both train and test data
train_data = pd.read_csv('train.csv')
test_data = pd.read_csv('test.csv')

# Check first 20 rows of train data
train_data.head(20)

# Check first 20 rows of test data
test_data.head(20) # Test data does not have the revenue_category

# Check the info of train and test data
train_data.info() # 22 columns
test_data.info() # 21 columns excluding the target variable(revenue_category)

# Check for missing values in train & test data
train_data.isnull().sum()
train_data.isnull().sum()

# Visualize the distribution of revenue categories
plt.figure(figsize=(6, 4))
sns.countplot(x='revenue_category', data=train_data)
plt.title('Revenue Categories Distribution')
plt.xlabel('Revenue Category')
plt.ylabel('Frequency')
plt.show()

# Fill missing values in numeric columns with the median value
train_data.fillna(train_data.median(numeric_only=True), inplace=True)
test_data.fillna(test_data.median(numeric_only=True), inplace=True)

train_data.isnull().sum()

# Drop missing values in release_date and language columns.
train_data.dropna(subset=['release_date', 'language'])
test_data.dropna(subset=['release_date', 'language'])

#convert date to datetime and extract year and month
# Also encode categorical variables using the LabelEncoder
# Define a function to pre-process this data
def transform_data(pro_data):
    # Convert date columns to datetime
    for date_column in ['release_date', 'dvd_release_date']:
        pro_data[date_column] = pd.to_datetime(pro_data[date_column], errors='coerce', format='%d-%b-%y')

    # Extract year and month
    pro_data['release_year'] = pro_data['release_date'].dt.year
    pro_data['release_month'] = pro_data['release_date'].dt.month
    pro_data['dvd_release_year'] = pro_data['dvd_release_date'].dt.year
    pro_data['dvd_release_month'] = pro_data['dvd_release_date'].dt.month


    # Convert runtime to numeric (remove ' min' and convert to integer)
    pro_data['runtime'] = pro_data['runtime'].str.replace(' min', '').astype(float)

    # Handle other numeric columns with potential non-numeric values
    for col in ['users_votes', 'ratings_imdb', 'ratings_tomatoes', 'ratings_metacritic']:
        pro_data[col] = pro_data[col].str.extract('(\d+\.?\d*)').astype(float)


    for column in ['country', 'genres', 'language', 'censor_rating']:
        le = LabelEncoder()
        pro_data[column] = le.fit_transform(pro_data[column].astype(str))
    return pro_data

# Apply the defined function on train and test data
train_data = transform_data(train_data)
test_data = transform_data(test_data)

# Impute missing values in numeric columns. This will tackle missing values in Censor ratings column
imputer = SimpleImputer(strategy='median')
numeric_cols = train_data.select_dtypes(include=['float64', 'int64']).columns
train_data[numeric_cols] = imputer.fit_transform(train_data[numeric_cols])
test_data[numeric_cols] = imputer.transform(test_data[numeric_cols])

# drop original date columns
train_data.drop(['release_date', 'dvd_release_date'], axis=1, inplace=True)

# drop original date columns in test data
test_data.drop(['release_date', 'dvd_release_date'], axis=1, inplace=True)

train_data.info()

# Encode revenue_category to numeric values
train_data['revenue_category'] = train_data['revenue_category'].map({'High': 1, 'Low': 0})

# Define the target and features
X = train_data.drop(['title', 'revenue_category'], axis=1) # feature variables
y = train_data['revenue_category'] # Target Variables

# Split the training data for validation
# The ideal split percentage is 80% train(0.8) and 20% test(0.2)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Initiate and train the Random Forest classifier model
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42) # Initializing Random Forest
rf_classifier.fit(X_train, y_train) # Model and fit the model to the training data

# Get feature importances
feat_importance = rf_classifier.feature_importances_
features = X.columns
feat_importance_df = pd.DataFrame({'feature': features, 'importance': feat_importance})
feat_importance_df.sort_values(by='importance', ascending=False, inplace=True)

# Plot feature importances
plt.figure(figsize=(10, 8))
sns.barplot(x='importance', y='feature', data=feat_importance_df)
plt.title('Feature Importances')
plt.show() # From the plot we see the important features that affect revenue_category

# Select top N features
N = 10  # Adjust N to select the top N features
top_feat = feat_importance_df.head(N)['feature'].tolist() # Get the top N features(top 10)
X_train_selected = X_train[top_feat] # Top features of the X_train dataframe
X_val_selected = X_val[top_feat] # Top features of the X_val dataframe
test_data_selected = test_data[top_feat] # Top features of the test data

# Retrain the model with selected features
rf_classifier.fit(X_train_selected, y_train)

# Validate the model with selected features
y_predict = rf_classifier.predict(X_val_selected)
print("Validation Accuracy score using top features:", accuracy_score(y_val, y_predict)) #85% accuracy score

# Predict on the test set with selected features
test_data['revenue_category'] = rf_classifier.predict(test_data_selected)

# Save the predictions
test_data[['title', 'revenue_category']].to_csv('submission.csv', index=False)
print("Predictions of Movie Licensing submission.csv")

# Import classification report, roc_auc_score to evaluate model performance
from sklearn.metrics import classification_report, roc_auc_score, roc_curve

# Classification report including precision, recall, and F1-score
print("Classification Report:")
print(classification_report(y_val, y_predict, target_names=['Low', 'High']))
# The F1 SCORE provides an equilibrum between precision and recall. For both high and low revenue categories
# we have 0.86.

# Evaluate the model using additional metrics
y_val_pred_prob = rf_classifier.predict_proba(X_val_selected)[:, 1]

# ROC AUC Score
roc_auc = roc_auc_score(y_val, y_val_pred_prob)
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve
fpr, tpr, thresholds = roc_curve(y_val, y_val_pred_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()

"""**The AUC score and curve indicates that the model has a high chance of distinguishing a positive class from a negative one. A 0.92 AUC score generally indicates a model that has a high classification strength meaning there is a low probablity of picking a false positive or a false negative**"""

